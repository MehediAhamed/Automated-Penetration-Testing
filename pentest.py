import streamlit as st
import lmstudio as lms
import contextlib
import io
import textwrap



LMSTUDIO_HOST = "172.17.212.79:1234"

st.set_page_config(page_title="Automated Penetration Testing", page_icon="ðŸ›¡ï¸", layout="wide")
st.title("ðŸ›¡ï¸ Automated Penetration Testing")
st.caption("Authorized â€¢ Defensive â€¢ Educational Penetration Testing Assistant")


@st.cache_resource
def get_model():
    client = lms.Client(LMSTUDIO_HOST)
    model = client.llm.model("armurai_-_pentest_ai")
    return model

model = get_model()


st.sidebar.header("ðŸ§­ Pentest Controls")
MODE = st.sidebar.selectbox(
    "Assessment Mode",
    [
        "General Security",
        "Web Application",
        "Network / Infrastructure",
        "Cloud Security",
        "Threat Modeling",
        "Report Writing"
    ]
)
ALLOW_CODE = st.sidebar.checkbox(
    "Enable Python Analysis Sandbox",
    value=False,
    help="Allows safe Python execution (no system/network access)"
)
CLEAR_CHAT = st.sidebar.button("ðŸ§¹ Clear Chat")


SYSTEM_PROMPT = f"""
You are Automated Penetration Testing, a professional penetration testing assistant.

Mode: {MODE}

Rules:
- Educational & defensive use only
- No live exploit payloads or weaponized commands
- No step-by-step hacking instructions
- Explain risks, detection, and remediation
- Assume legal authorization exists
- If code is requested, provide SAFE analysis-only examples
"""



if CLEAR_CHAT or "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ]
    st.session_state.report_notes = []

for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

user_input = st.chat_input("Ask about security testing, risks, or defenses...")


def safe_exec(code: str) -> str:
    allowed_builtins = {
        "range": range,
        "len": len,
        "sum": sum,
        "min": min,
        "max": max,
        "sorted": sorted,
        "print": print
    }
    output = io.StringIO()
    try:
        with contextlib.redirect_stdout(output):
            exec(code, {"__builtins__": allowed_builtins}, {})
    except Exception as e:
        return f"Execution error: {e}"
    return output.getvalue() or "Code executed successfully."



if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    conversation = {"messages": st.session_state.messages}

    chat = lms.Chat.from_history(conversation)

    with st.chat_message("assistant"):
        with st.spinner("Ai analyzing..."):
            result = model.respond(chat)
            response = result.content

        st.markdown(response)

        if ALLOW_CODE and "```python" in response:
            st.divider()
            st.subheader("Sandbox Execution Result")

            code = response.split("```python")[1].split("```")[0]
            code = textwrap.dedent(code)
            st.code(code, language="python")
            out = safe_exec(code)
            st.text(out)

        if MODE == "Report Writing":
            st.session_state.report_notes.append(response)

    st.session_state.messages.append({"role": "assistant", "content": response})


if MODE == "Report Writing" and st.session_state.report_notes:
    st.sidebar.divider()
    st.sidebar.subheader("Pentest Report")
    if st.sidebar.button("Generate Draft Report"):
        report = "\n\n".join(st.session_state.report_notes)
        st.sidebar.download_button(
            label="â¬‡Download Report (TXT)",
            data=report,
            file_name="pentest_report.txt",
            mime="text/plain"
        )
